{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c3f9af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################\n",
    "import csv\n",
    "import cv2\n",
    "import os\n",
    "import requests\n",
    "import numpy as np \n",
    "import imutils \n",
    "import cv2\n",
    "import torch\n",
    "# from upload_attendence import *\n",
    "from facenet_pytorch import MTCNN\n",
    "url = \"http://192.168.100.138:8080/shot.jpg\"\n",
    "import pickle\n",
    "import time\n",
    "from threading import Thread\n",
    "import threading\n",
    "import os\n",
    "import cvzone\n",
    "from datetime import datetime,timedelta\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import upload_attendence\n",
    "\n",
    "# def task1():\n",
    "# cap=cv2.VideoCapture(0)\n",
    "# cap.set(cv2.CAP_PROP_FPS, 144)\n",
    "# cap.set(3,140)\n",
    "# cap.set(4,20)\n",
    "imgB_size=cv2.imread(\"layout.png\")\n",
    "height, width, channels = imgB_size.shape\n",
    "\n",
    "width, height = 600, 395\n",
    "width1, height1 =460, 395\n",
    "\n",
    "# print(imgB_size.shape)\n",
    "imgB_ = cv2.resize(imgB_size, (1565,795))\n",
    "\n",
    "# folderModePath=\"resources/modes/\"\n",
    "folderModePath=\"faces_detected/\"\n",
    "modePathList=os.listdir(folderModePath)\n",
    "imgModeList=[]\n",
    "paths1=[]\n",
    "for path in modePathList:\n",
    "    imgModeList.append(cv2.imread(os.path.join(folderModePath,path)))\n",
    "    paths1.append(path)\n",
    "\n",
    "\n",
    "\n",
    "paths2=[]\n",
    "folderImagePath=\"faces_detected/\"\n",
    "modeImageList=os.listdir(folderImagePath)\n",
    "imageList=[]\n",
    "for path in modeImageList:\n",
    "    imageList.append(cv2.imread(os.path.join(folderImagePath,path)))\n",
    "    paths2.append(path)\n",
    "print(paths2)\n",
    "\n",
    "paths3=[]\n",
    "folderImagePath=\"face_detected3/\"\n",
    "modeImageList1=os.listdir(folderImagePath)\n",
    "for path in modeImageList1:\n",
    "    paths3.append(path)\n",
    "print(len(paths3))\n",
    "superb=paths3.copy()\n",
    "\n",
    "\n",
    "\n",
    "employee=paths2.copy()\n",
    "print(employee)\n",
    "count=0\n",
    "now=datetime.now()\n",
    "\n",
    "current_date=now.strftime(\"%Y-%m-%d\")\n",
    "print(current_date)\n",
    "\n",
    "# with open(current_date+'.csv', 'w+', newline='') as f:\n",
    "#     writer = csv.writer(csvfile)\n",
    "\n",
    "f=open(current_date+'.csv','a',newline='')\n",
    "writer=csv.writer(f)\n",
    "\n",
    "# load encoding file\n",
    "file=open(\"EncodeFile.p\",\"rb\")\n",
    "encodeListknownId=pickle.load(file)\n",
    "file.close()\n",
    "encodeListknown,studentId=encodeListknownId\n",
    "# print(studentId)\n",
    "print(\"Encode File Load!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "file=open(\"EncodeFile2.p\",\"rb\")\n",
    "encodeListKnownId=pickle.load(file)\n",
    "file.close()\n",
    "encodeListKnown,StudentId=encodeListKnownId\n",
    "# print(studentId)\n",
    "print(\"Encode File Load!\")\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "while True:\n",
    "    success,img=cap.read()\n",
    "    \n",
    "#     img_resp = requests.get(url) \n",
    "#     img_arr = np.array(bytearray(img_resp.content), dtype=np.uint8) \n",
    "#     img = cv2.imdecode(img_arr, -1) \n",
    "#     img = imutils.resize(img, width=1000, height=1800) \n",
    "    \n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur to remove noise\n",
    "    blur_img = cv2.GaussianBlur(gray_img, (5, 5), 0)\n",
    "\n",
    "    # Apply histogram equalization to improve contrast\n",
    "    eq_img = cv2.equalizeHist(blur_img)\n",
    "\n",
    "    # Apply non-local means filtering for denoising\n",
    "    nlm_img = cv2.fastNlMeansDenoising(eq_img, None, 10, 7, 21)\n",
    "\n",
    "    # Apply gamma correction for image enhancement\n",
    "    gamma = 0.5\n",
    "    gamma_img = cv2.pow(nlm_img/255.0, gamma)\n",
    "    gamma_img = (gamma_img*255).astype('uint8')\n",
    "    \n",
    "    scale_factor = 2.0\n",
    "    \n",
    "    # Resize the image\n",
    "    resized_img = cv2.resize(gamma_img, (0,0), fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_LINEAR)\n",
    "    rgb_img = cv2.cvtColor(resized_img, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    imgs=cv2.resize(rgb_img,(0,0),None,0.25,0.25)\n",
    "    imgs=cv2.cvtColor(imgs,cv2.COLOR_BGR2RGB) #face detection takes RGB\n",
    "\n",
    "    faceCurFrame=face_recognition.face_locations(imgs)\n",
    "    encodeCurFrame=face_recognition.face_encodings(imgs,faceCurFrame)\n",
    "\n",
    "    img1= cv2.resize(rgb_img, (width, height))\n",
    "    imgB_[260:height+260, 50:50+width] = img1\n",
    "\n",
    "    if len(faceCurFrame)!=0:\n",
    "\n",
    "        \n",
    "        for encodeFace,faceLoc in zip(encodeCurFrame,faceCurFrame): #simultaneously run for loop\n",
    "            matches=face_recognition.compare_faces(encodeListknown,encodeFace)\n",
    "            faceDis=face_recognition.face_distance(encodeListknown,encodeFace)\n",
    "            print(\"matches:\",matches)\n",
    "    #         print(\"FaceDist:\",faceDis)\n",
    "\n",
    "            matchIndex=np.argmin(faceDis)\n",
    "            print(\"MatchIndex:\",matchIndex)\n",
    "            \n",
    "            \n",
    "            image=cv2.imread((\"resources/attendence_mark.png\"))\n",
    "            c=cv2.imread(\"resources/modes/dash.png\")\n",
    "            m=cv2.imread(\"resources/modes/active.png\")\n",
    "            if True in matches:\n",
    "                m=None\n",
    "\n",
    "                img_New=\"faces_detected/\"+paths2[matchIndex]\n",
    "                if paths2[matchIndex] in employee:\n",
    "                    time.sleep(1)\n",
    "                    img_new=cv2.imread(str(img_New))\n",
    "                    widthw,heighth,_=img_new.shape\n",
    "\n",
    "#                     img_= cv2.resize(img_new, (widthw, heighth))\n",
    "\n",
    "#                     widthh,heighthh,_=img_.shape\n",
    "\n",
    "                    imgB_[180:180+(widthw), 1000:1000+(heighth)] = img_new\n",
    "\n",
    "                    employee.remove(paths2[matchIndex])\n",
    "                    print(employee)\n",
    "                    y1,x2,y2,x1=faceLoc\n",
    "\n",
    "                    y1,x2,y2,x1= y1*4,x2*4,y2*4,x1*4\n",
    "\n",
    "                    bbox = 50+x1,172+y1,x2-x1,y2-y1\n",
    "\n",
    "                    imgB_ =cvzone.cornerRect(imgB_,bbox,rt=0)\n",
    "\n",
    "                    widthh,heighthh,_=image.shape\n",
    "\n",
    "\n",
    "                    imgB_[260:260+(widthh), 1200:1200+(heighthh)] = image\n",
    "\n",
    "                    w,h,_=c.shape\n",
    "                    new=cv2.resize(c,(widthh,heighthh))\n",
    "                    \n",
    "                    current_time=now.strftime(\"%H-%M-%S\")\n",
    "                    print(current_time)\n",
    "                    \n",
    "                    with open('attendence.csv', 'a') as f:\n",
    "                        writer=csv.writer(f)\n",
    "                        writer.writerow([paths2[matchIndex],current_date,current_time])\n",
    "                    \n",
    "                else:\n",
    "                \n",
    "                    y1,x2,y2,x1=faceLoc\n",
    "\n",
    "                    y1,x2,y2,x1= y1*4,x2*4,y2*4,x1*4\n",
    "\n",
    "                    bbox = 50+x1,172+y1,x2-x1,y2-y1\n",
    "\n",
    "                    imgB_ =cvzone.cornerRect(imgB_,bbox,rt=0)\n",
    "\n",
    "                    n=image\n",
    "                    w,h,_=n.shape\n",
    "                    new=cv2.resize(image,(w,h))\n",
    "                    imgB=cv2.imread(\"layout.png\")\n",
    "                    imgB_ = cv2.resize(imgB_size, (1565,795))\n",
    "                    img=cv2.resize(img,(width, height))\n",
    "                    imgB_[260:height+260, 50:50+width] = img\n",
    "\n",
    "                    imgB_[260:260+(w), 1200:1200+(h)] =new\n",
    "\n",
    "            else:\n",
    "                \n",
    "                for encodeFace,faceLoc in zip(encodeCurFrame,faceCurFrame): #simultaneously run for loop\n",
    "                    matches1=face_recognition.compare_faces(encodeListKnown,encodeFace)\n",
    "                    faceDis=face_recognition.face_distance(encodeListKnown,encodeFace)\n",
    "                    print(\"matches:\",matches1)\n",
    "            #         print(\"FaceDist:\",faceDis)\n",
    "                    \n",
    "#                     matchIndex=np.argmin(faceDis)\n",
    "#                     print(\"MatchIndex:\",matchIndex)\n",
    "\n",
    "\n",
    "                    image=cv2.imread((\"resources/attendence_mark.png\"))\n",
    "                    c=cv2.imread(\"resources/modes/dash.png\")\n",
    "                    m=cv2.imread(\"resources/modes/active.png\")\n",
    "                    if True in matches1:\n",
    "                        matchIndex=np.argmin(faceDis)\n",
    "                        print(\"MatchIndex:\",matchIndex)\n",
    "                        m=None\n",
    "                        img_New=\"face_detected3/\"+paths3[matchIndex]\n",
    "\n",
    "                        img_new=cv2.imread(str(img_New))\n",
    "                        widthw,heighth,_=img_new.shape\n",
    "\n",
    "                        imgB_[180:180+(widthw), 1000:1000+(heighth)] = img_new\n",
    "\n",
    "#                             superb.remove(paths3[matchIndex])\n",
    "#                             print(superb)\n",
    "                        y1,x2,y2,x1=faceLoc\n",
    "\n",
    "                        y1,x2,y2,x1= y1*4,x2*4,y2*4,x1*4\n",
    "\n",
    "                        bbox = 50+x1,172+y1,x2-x1,y2-y1\n",
    "\n",
    "                        imgB_ =cvzone.cornerRect(imgB_,bbox,rt=0)\n",
    "\n",
    "                        widthh,heighthh,_=image.shape\n",
    "\n",
    "\n",
    "                        imgB_[260:260+(widthh), 1200:1200+(heighthh)] = image\n",
    "\n",
    "                        w,h,_=c.shape\n",
    "                        new=cv2.resize(c,(widthh,heighthh))\n",
    "\n",
    "                        current_time=now.strftime(\"%H-%M-%S\")\n",
    "                        print(current_time)\n",
    "\n",
    "                        with open('attendence2.csv', 'a') as f:\n",
    "                            writer=csv.writer(f)\n",
    "                            writer.writerow([paths2[matchIndex],current_date,current_time])  \n",
    "                    else:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        folder_path = \"face_detected2/\"\n",
    "                        file_count = len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n",
    "\n",
    "\n",
    "\n",
    "                        filename = f'face_detected2/face_{file_count}.jpg'\n",
    "                        file_count+=1\n",
    "                        cv2.imwrite(filename, rgb_img)\n",
    "                        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "                        mtcnn = MTCNN(keep_all=True, device=device)\n",
    "\n",
    "                        # Set minimum and maximum face sizes and confidence threshold\n",
    "                        min_face_size = 0\n",
    "                        max_face_size = 1000\n",
    "                        confidence_threshold = [0.9, 0.95, 0.95]\n",
    "                        rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                        # Detect faces in the RGB frame using the MTCNN detector\n",
    "                        boxes, _ = mtcnn.detect(rgb, landmarks=False)\n",
    "\n",
    "\n",
    "                        # Get the average face size in the current frame\n",
    "                        if boxes is not None:\n",
    "                            face_sizes = [box[2] - box[0] for box in boxes]\n",
    "                            if len(face_sizes) > 0:\n",
    "                                avg_face_size = sum(face_sizes) / len(face_sizes)\n",
    "                                min_face_size = max(30, int(avg_face_size * 0.7))\n",
    "                                max_face_size = int(avg_face_size * 1.3)\n",
    "\n",
    "                        folder_path = \"face_detected3/\"\n",
    "                        file_count1 = len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n",
    "\n",
    "                        cunts=file_count1\n",
    "                        # Draw rectangles around the detected faces\n",
    "                        if boxes is not None:\n",
    "\n",
    "                            for box in boxes:\n",
    "                                x1, y1, x2, y2 = box.astype('int')\n",
    "                                face_size = x2 - x1\n",
    "                                if min_face_size <= face_size <= max_face_size:\n",
    "                                    cv2.rectangle(img, (x1-50, y1-50), (x2+50, y2+50), (0, 255, 0), 2)\n",
    "\n",
    "                                    face = img[y1:y2, x1:x2]\n",
    "\n",
    "                                    filename = f'face_detected3/face_{cunts}.jpg'\n",
    "                                    cv2.imwrite(filename, face)\n",
    "                                    cunts+=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    count+=1\n",
    "                    n=image\n",
    "                    image=None\n",
    "                    c=None\n",
    "\n",
    "                    m=cv2.imread(\"resources/modes/active.png\")\n",
    "\n",
    "                    w,h,_=n.shape\n",
    "                    new=cv2.resize(m,(w,h))\n",
    "                    imgB=cv2.imread(\"layout.png\")\n",
    "                    imgB_ = cv2.resize(imgB_size, (1565,795))\n",
    "                    img=cv2.resize(img,(width, height))\n",
    "                    imgB_[260:height+260, 50:50+width] = img\n",
    "\n",
    "                    imgB_[260:260+(w), 1200:1200+(h)] =new\n",
    "    else:\n",
    "        imgB=cv2.imread(\"layout.png\")\n",
    "        imgB_ = cv2.resize(imgB_size, (1565,795))\n",
    "        img=cv2.resize(img,(width, height))\n",
    "        imgB_[260:height+260, 50:50+width] = img\n",
    "\n",
    "    cv2.imshow(\"Img\",imgB_)\n",
    "    if cv2.waitKey(1)==27:\n",
    "        img=None\n",
    "        break\n",
    "# cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "# image.upload()\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f65dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
